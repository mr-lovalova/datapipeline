[build-system]
requires = ["setuptools>=64", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "jerry-thomas"
version = "2.0.1"
description = "Jerry-Thomas: a stream-first, plugin-friendly data pipeline (mixology-themed CLI)"
readme = { file = "README.md", content-type = "text/markdown" }
requires-python = ">=3.10"
license = { text = "MIT" }
authors = [{ name = "Anders Skott Lind" }]
urls = { "Homepage" = "https://github.com/mr-lovalova/datapipeline", "Repository" = "https://github.com/mr-lovalova/datapipeline", "Issues" = "https://github.com/mr-lovalova/datapipeline/issues" }
dependencies = [
  "numpy>=1.24,<3.0",
  "pydantic>=2.0",
  "PyYAML>=5.4",
  "tqdm>=4.0",
  "jinja2>=3.0",
  "rich>=13",
]

[project.optional-dependencies]
# Extra helpers for ML adapters in datapipeline.integrations
ml = [
  "pandas>=2.0",
  "torch>=2.0",
]

[project.scripts]
jerry = "datapipeline.cli.app:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
datapipeline = [
  "templates/dataset_config.yaml",
  "templates/plugin_skeleton/**",
  "templates/demo_skeleton/**",
  "templates/stubs/**"
]

[project.entry-points."datapipeline.filters"]

[project.entry-points."datapipeline.transforms.record"]
lag = "datapipeline.transforms.record.lag:LagRecordTransform"
floor_time = "datapipeline.transforms.record.floor_time:FloorTimeRecordTransform"
filter = "datapipeline.transforms.filter:filter"

[project.entry-points."datapipeline.transforms.stream"]
floor_time = "datapipeline.transforms.stream.floor_time:FloorTimeTransform"
lag = "datapipeline.transforms.stream.lag:LagTransform"
ensure_cadence = "datapipeline.transforms.stream.ensure_ticks:EnsureCadenceTransform"
fill = "datapipeline.transforms.stream.fill:FillTransformer"
granularity = "datapipeline.transforms.stream.granularity:FeatureGranularityTransform"
lint = "datapipeline.transforms.stream.lint:StreamLint"
dedupe = "datapipeline.transforms.stream.dedupe:FeatureDeduplicateTransform"
rolling = "datapipeline.transforms.stream.rolling:RollingTransformer"
filter = "datapipeline.transforms.stream.filter:FilterTransform"

[project.entry-points."datapipeline.transforms.feature"]
scale = "datapipeline.transforms.feature.scaler:StandardScalerTransform"
sequence = "datapipeline.transforms.sequence:WindowTransformer"


[project.entry-points."datapipeline.transforms.vector"]
drop = "datapipeline.transforms.vector:VectorDropTransform"
fill = "datapipeline.transforms.vector:VectorFillTransform"
replace = "datapipeline.transforms.vector:VectorReplaceTransform"

[project.entry-points."datapipeline.mappers"]
"time.synthetic" = "datapipeline.mappers.noop:identity"
encode_time = "datapipeline.mappers.synthetic.time:encode"
identity = "datapipeline.mappers.noop:identity"

[project.entry-points."datapipeline.loaders"]
"core.io" = "datapipeline.sources.factory:build_loader"
"core.foreach" = "datapipeline.sources.foreach:ForeachLoader"
"core.synthetic.ticks" = "datapipeline.sources.synthetic.time.loader:make_time_loader"

[project.entry-points."datapipeline.parsers"]
identity = "datapipeline.parsers.identity:IdentityParser"
"core.synthetic.ticks" = "datapipeline.sources.synthetic.time.parser:TimeRowParser"

[tool.pytest.ini_options]
pythonpath = ["src"]
[project.entry-points."datapipeline.transforms.debug"]
identity = "datapipeline.transforms.debug.identity:IdentityGuardTransform"
lint = "datapipeline.transforms.debug.lint:StreamLint"
